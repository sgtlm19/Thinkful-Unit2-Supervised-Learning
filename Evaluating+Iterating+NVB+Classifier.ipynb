{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Iterate & Evaluate Classifier #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate & Evaluate Classifier on Yelp Feedback ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by Lorenz Madarang ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: https://archive.ics.uci.edu/ml/machine-learning-databases/00331/ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import .txt files and create two columns for the message and the sentiment\n",
    "sentiment_raw = pd.read_csv('yelp_labelled.txt', delimiter= '\\t', header=None)\n",
    "sentiment_raw.columns = ['message', 'sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Naive Bayes Classifier with Positive Keywords list length of 23 words ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords list length is 23 words long\n"
     ]
    }
   ],
   "source": [
    "keywords = ['great', 'friendly', 'delicious', 'Great', 'nice', 'love', 'excellent', 'awesome', 'fantastic', 'tasty', 'stars', '5', 'Best', 'clean', 'perfect', 'loved', 'tender', 'attentive', 'wonderful', 'Good', 'recommend', 'enjoyed', 'deal']\n",
    "print('Keywords list length is {} words long'.format(len(keywords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sentiment_raw[str(key)] = sentiment_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sentiment_raw[keywords]\n",
    "target = sentiment_raw['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 343\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.67\n",
      "Testing on Sample: 0.657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63,  0.67,  0.65,  0.61,  0.65,  0.62,  0.71,  0.67,  0.64,  0.7 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity is 0.8792270531400966\n",
      "Specificity is 0.5989911727616646\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(target, y_pred)\n",
    "matrix = confusion_matrix(target, y_pred)\n",
    "print('Sensitivity is {}'.format(matrix[1,1]/(matrix[0,1]+matrix[1,1])))\n",
    "print('Specificity is {}'.format(matrix[0,0]/(matrix[0,0]+matrix[1,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier seems to be consistent when I conduct a one time holdout of 20% but when we conduct a cross-validation with 10 folds the accuracy scores seems to fluctuate.  The sensitivity is pretty good but the specificty is not so good for this classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Naive Bayes Classifier with Positive Keywords list length of 10 words ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = ['great', 'friendly', 'delicious', 'Great', 'nice', 'love', 'excellent', 'awesome', 'fantastic', 'tasty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 408\n"
     ]
    }
   ],
   "source": [
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sentiment_raw[str(key)] = sentiment_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "data = sentiment_raw[keywords]\n",
    "target = sentiment_raw['sentiment']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.595\n",
      "Testing on Sample: 0.592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.59,  0.57,  0.57,  0.55,  0.6 ,  0.54,  0.64,  0.59,  0.6 ,  0.65])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity is 0.9339622641509434\n",
      "Specificity is 0.5514541387024608\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(target, y_pred)\n",
    "matrix = confusion_matrix(target, y_pred)\n",
    "print('Sensitivity is {}'.format(matrix[1,1]/(matrix[0,1]+matrix[1,1])))\n",
    "print('Specificity is {}'.format(matrix[0,0]/(matrix[0,0]+matrix[1,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier seems to be consistent when I conduct a one time holdout of 20% but when we conduct a cross-validation with 10 folds the accuracy scores seems to fluctuate.  The sensitivity is better than the first classifier but the specificty is a little bit worse for this classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Naive Bayes Classifier with Positive Keywords list length of 5 words ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = ['great', 'friendly', 'delicious', 'Great', 'nice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 435\n"
     ]
    }
   ],
   "source": [
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sentiment_raw[str(key)] = sentiment_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "data = sentiment_raw[keywords]\n",
    "target = sentiment_raw['sentiment']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.565\n",
      "Testing on Sample: 0.565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.59,  0.54,  0.56,  0.51,  0.57,  0.52,  0.62,  0.56,  0.58,  0.6 ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity is 0.9452054794520548\n",
      "Specificity is 0.535059331175836\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(target, y_pred)\n",
    "matrix = confusion_matrix(target, y_pred)\n",
    "print('Sensitivity is {}'.format(matrix[1,1]/(matrix[0,1]+matrix[1,1])))\n",
    "print('Specificity is {}'.format(matrix[0,0]/(matrix[0,0]+matrix[1,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier seems to be consistent when I conduct a one time holdout of 20% but when we conduct a cross-validation with 10 folds the accuracy scores seems to fluctuate.  The sensitivity is better than the first classifier but the specificty is a little bit worse for this classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Naive Bayes Classifier with Positive Keywords list length of 215 words ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords list length is 215 words long\n"
     ]
    }
   ],
   "source": [
    "keywords = ['and',\n",
    " 'the',\n",
    " 'was',\n",
    " 'I',\n",
    " 'a',\n",
    " 'is',\n",
    " 'The',\n",
    " 'to',\n",
    " 'good',\n",
    " 'in',\n",
    " 'place',\n",
    " 'food',\n",
    " 'it',\n",
    " 'of',\n",
    " 'great',\n",
    " 'this',\n",
    " 'with',\n",
    " 'for',\n",
    " 'very',\n",
    " 'had',\n",
    " 'are',\n",
    " 'you',\n",
    " 'service',\n",
    " 'were',\n",
    " 'have',\n",
    " 'so',\n",
    " 'on',\n",
    " 'This',\n",
    " 'here',\n",
    " 'friendly',\n",
    " 'my',\n",
    " 'amazing',\n",
    " 's',\n",
    " 'be',\n",
    " 'that',\n",
    " 'back',\n",
    " 'time',\n",
    " 'really',\n",
    " 'they',\n",
    " 'delicious',\n",
    " 'we',\n",
    " 'but',\n",
    " 'all',\n",
    " 'Great',\n",
    " 'nice',\n",
    " 't',\n",
    " 'like',\n",
    " 'our',\n",
    " 'also',\n",
    " 'just',\n",
    " 'not',\n",
    " 'restaurant',\n",
    " 'go',\n",
    " 'staff',\n",
    " 'We',\n",
    " 'as',\n",
    " 'Vegas',\n",
    " 'at',\n",
    " 'love',\n",
    " 'an',\n",
    " 'will',\n",
    " 'They',\n",
    " 'menu',\n",
    " 'Service',\n",
    " 'first',\n",
    " 'their',\n",
    " 'best',\n",
    " 'experience',\n",
    " 'It',\n",
    " 'made',\n",
    " 'can',\n",
    " 'by',\n",
    " 'My',\n",
    " 'been',\n",
    " 'fresh',\n",
    " 'out',\n",
    " 'steak',\n",
    " 'excellent',\n",
    " 'even',\n",
    " 'always',\n",
    " 'atmosphere',\n",
    " 'awesome',\n",
    " 'has',\n",
    " 'which',\n",
    " 'only',\n",
    " 'definitely',\n",
    " 'your',\n",
    " 'fantastic',\n",
    " 'ever',\n",
    " 'pizza',\n",
    " 'selection',\n",
    " 'chicken',\n",
    " 'could',\n",
    " 'server',\n",
    " 'came',\n",
    " 'he',\n",
    " 'again',\n",
    " 'what',\n",
    " 'well',\n",
    " 'pretty',\n",
    " 'say',\n",
    " 'breakfast',\n",
    " 'up',\n",
    " 'one',\n",
    " 'get',\n",
    " 'spot',\n",
    " 'm',\n",
    " 'some',\n",
    " 'or',\n",
    " 'happy',\n",
    " 'prices',\n",
    " 'there',\n",
    " 'beer',\n",
    " 'did',\n",
    " 'want',\n",
    " 'tasty',\n",
    " 'us',\n",
    " 'when',\n",
    " 'Their',\n",
    " 'stars',\n",
    " '5',\n",
    " 've',\n",
    " 'Best',\n",
    " 'Food',\n",
    " 'town',\n",
    " 'night',\n",
    " 'come',\n",
    " 'every',\n",
    " 'clean',\n",
    " 'eat',\n",
    " 'Very',\n",
    " 'about',\n",
    " 'taste',\n",
    " 'from',\n",
    " 'me',\n",
    " 'perfect',\n",
    " 'loved',\n",
    " 'right',\n",
    " 'quality',\n",
    " 'tender',\n",
    " 'attentive',\n",
    " 'If',\n",
    " 'sandwich',\n",
    " 'salad',\n",
    " 'inside',\n",
    " 'wonderful',\n",
    " 'sauce',\n",
    " 'd',\n",
    " 'went',\n",
    " 'still',\n",
    " 'buffet',\n",
    " 'All',\n",
    " 'spicy',\n",
    " 'Good',\n",
    " 'sushi',\n",
    " 'than',\n",
    " 'while',\n",
    " 'quite',\n",
    " 'order',\n",
    " 'would',\n",
    " 'recommend',\n",
    " 'family',\n",
    " 'A',\n",
    " 'tried',\n",
    " 'So',\n",
    " 'thing',\n",
    " 'cooked',\n",
    " 'any',\n",
    " 'side',\n",
    " 'ordered',\n",
    " 'way',\n",
    " 'Our',\n",
    " 'meal',\n",
    " 'next',\n",
    " 'worth',\n",
    " 'ambiance',\n",
    " 'day',\n",
    " 'since',\n",
    " 'going',\n",
    " 'dish',\n",
    " 'bread',\n",
    " 'them',\n",
    " 'enough',\n",
    " 'twice',\n",
    " 'absolutely',\n",
    " 'more',\n",
    " 'disappointed',\n",
    " 'reasonable',\n",
    " 'little',\n",
    " 'll',\n",
    " 'enjoyed',\n",
    " 'bar',\n",
    " 'super',\n",
    " 'fries',\n",
    " 'too',\n",
    " 'deal',\n",
    " 'visit',\n",
    " 'his',\n",
    " 'table',\n",
    " 'huge',\n",
    " 'sweet',\n",
    " 'potato',\n",
    " 'lunch',\n",
    " 'try',\n",
    " 'Everything',\n",
    " 're',\n",
    " 'price',\n",
    " 'dishes',\n",
    " 'better',\n",
    " 'Nice',\n",
    " 'steaks',\n",
    " 'hit',\n",
    " 'other',\n",
    " 'i',\n",
    " 'feel',]\n",
    "print('Keywords list length is {} words long'.format(len(keywords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 244\n"
     ]
    }
   ],
   "source": [
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sentiment_raw[str(key)] = sentiment_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "data = sentiment_raw[keywords]\n",
    "target = sentiment_raw['sentiment']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.675\n",
      "Testing on Sample: 0.756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.67,  0.67,  0.69,  0.66,  0.68,  0.7 ,  0.71,  0.76,  0.68,  0.73])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[418,  82],\n",
       "       [162, 338]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity is 0.8047619047619048\n",
      "Specificity is 0.7206896551724138\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(target, y_pred)\n",
    "print('Sensitivity is {}'.format(matrix[1,1]/(matrix[0,1]+matrix[1,1])))\n",
    "print('Specificity is {}'.format(matrix[0,0]/(matrix[0,0]+matrix[1,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier seems to be overfitting the data when I conduct a one time holdout of 20% and when we conduct a cross-validation with 10 folds it also confirms that there could be overfitting.  The sensitivity is worse than the first three classifiers but the specificity is better than the first three classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Naive Bayes Classifier with Positive Keywords list length of 1000 words ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords list length is 1000 words long\n"
     ]
    }
   ],
   "source": [
    "keywords = ['and',\n",
    " 'the',\n",
    " 'was',\n",
    " 'I',\n",
    " 'a',\n",
    " 'is',\n",
    " 'The',\n",
    " 'to',\n",
    " 'good',\n",
    " 'in',\n",
    " 'place',\n",
    " 'food',\n",
    " 'it',\n",
    " 'of',\n",
    " 'great',\n",
    " 'this',\n",
    " 'with',\n",
    " 'for',\n",
    " 'very',\n",
    " 'had',\n",
    " 'are',\n",
    " 'you',\n",
    " 'service',\n",
    " 'were',\n",
    " 'have',\n",
    " 'so',\n",
    " 'on',\n",
    " 'This',\n",
    " 'here',\n",
    " 'friendly',\n",
    " 'my',\n",
    " 'amazing',\n",
    " 's',\n",
    " 'be',\n",
    " 'that',\n",
    " 'back',\n",
    " 'time',\n",
    " 'really',\n",
    " 'they',\n",
    " 'delicious',\n",
    " 'we',\n",
    " 'but',\n",
    " 'all',\n",
    " 'Great',\n",
    " 'nice',\n",
    " 't',\n",
    " 'like',\n",
    " 'our',\n",
    " 'also',\n",
    " 'just',\n",
    " 'not',\n",
    " 'restaurant',\n",
    " 'go',\n",
    " 'staff',\n",
    " 'We',\n",
    " 'as',\n",
    " 'Vegas',\n",
    " 'at',\n",
    " 'love',\n",
    " 'an',\n",
    " 'will',\n",
    " 'They',\n",
    " 'menu',\n",
    " 'Service',\n",
    " 'first',\n",
    " 'their',\n",
    " 'best',\n",
    " 'experience',\n",
    " 'It',\n",
    " 'made',\n",
    " 'can',\n",
    " 'by',\n",
    " 'My',\n",
    " 'been',\n",
    " 'fresh',\n",
    " 'out',\n",
    " 'steak',\n",
    " 'excellent',\n",
    " 'even',\n",
    " 'always',\n",
    " 'atmosphere',\n",
    " 'awesome',\n",
    " 'has',\n",
    " 'which',\n",
    " 'only',\n",
    " 'definitely',\n",
    " 'your',\n",
    " 'fantastic',\n",
    " 'ever',\n",
    " 'pizza',\n",
    " 'selection',\n",
    " 'chicken',\n",
    " 'could',\n",
    " 'server',\n",
    " 'came',\n",
    " 'he',\n",
    " 'again',\n",
    " 'what',\n",
    " 'well',\n",
    " 'pretty',\n",
    " 'say',\n",
    " 'breakfast',\n",
    " 'up',\n",
    " 'one',\n",
    " 'get',\n",
    " 'spot',\n",
    " 'm',\n",
    " 'some',\n",
    " 'or',\n",
    " 'happy',\n",
    " 'prices',\n",
    " 'there',\n",
    " 'beer',\n",
    " 'did',\n",
    " 'want',\n",
    " 'tasty',\n",
    " 'us',\n",
    " 'when',\n",
    " 'Their',\n",
    " 'stars',\n",
    " '5',\n",
    " 've',\n",
    " 'Best',\n",
    " 'Food',\n",
    " 'town',\n",
    " 'night',\n",
    " 'come',\n",
    " 'every',\n",
    " 'clean',\n",
    " 'eat',\n",
    " 'Very',\n",
    " 'about',\n",
    " 'taste',\n",
    " 'from',\n",
    " 'me',\n",
    " 'perfect',\n",
    " 'loved',\n",
    " 'right',\n",
    " 'quality',\n",
    " 'tender',\n",
    " 'attentive',\n",
    " 'If',\n",
    " 'sandwich',\n",
    " 'salad',\n",
    " 'inside',\n",
    " 'wonderful',\n",
    " 'sauce',\n",
    " 'd',\n",
    " 'went',\n",
    " 'still',\n",
    " 'buffet',\n",
    " 'All',\n",
    " 'spicy',\n",
    " 'Good',\n",
    " 'sushi',\n",
    " 'than',\n",
    " 'while',\n",
    " 'quite',\n",
    " 'order',\n",
    " 'would',\n",
    " 'recommend',\n",
    " 'family',\n",
    " 'A',\n",
    " 'tried',\n",
    " 'So',\n",
    " 'thing',\n",
    " 'cooked',\n",
    " 'any',\n",
    " 'side',\n",
    " 'ordered',\n",
    " 'way',\n",
    " 'Our',\n",
    " 'meal',\n",
    " 'next',\n",
    " 'worth',\n",
    " 'ambiance',\n",
    " 'day',\n",
    " 'since',\n",
    " 'going',\n",
    " 'dish',\n",
    " 'bread',\n",
    " 'them',\n",
    " 'enough',\n",
    " 'twice',\n",
    " 'absolutely',\n",
    " 'more',\n",
    " 'disappointed',\n",
    " 'reasonable',\n",
    " 'little',\n",
    " 'll',\n",
    " 'enjoyed',\n",
    " 'bar',\n",
    " 'super',\n",
    " 'fries',\n",
    " 'too',\n",
    " 'deal',\n",
    " 'visit',\n",
    " 'his',\n",
    " 'table',\n",
    " 'huge',\n",
    " 'sweet',\n",
    " 'potato',\n",
    " 'lunch',\n",
    " 'try',\n",
    " 'Everything',\n",
    " 're',\n",
    " 'price',\n",
    " 'dishes',\n",
    " 'better',\n",
    " 'Nice',\n",
    " 'steaks',\n",
    " 'hit',\n",
    " 'other',\n",
    " 'i',\n",
    " 'feel',\n",
    " 'down',\n",
    " 'area',\n",
    " 'how',\n",
    " 'dining',\n",
    " 'once',\n",
    " 'ice',\n",
    " 'incredible',\n",
    " 'bacon',\n",
    " 'Both',\n",
    " 'make',\n",
    " 'fun',\n",
    " 'chef',\n",
    " 'fast',\n",
    " 'far',\n",
    " 'You',\n",
    " 'wrong',\n",
    " 'didn',\n",
    " 'everything',\n",
    " 'check',\n",
    " 'won',\n",
    " 'authentic',\n",
    " 'times',\n",
    " 'if',\n",
    " 'options',\n",
    " 'quick',\n",
    " 'because',\n",
    " 'during',\n",
    " 'recommendation',\n",
    " 'beautiful',\n",
    " 'That',\n",
    " 'tacos',\n",
    " 'burger',\n",
    " 'found',\n",
    " 'Overall',\n",
    " 'lot',\n",
    " 'portions',\n",
    " 'moist',\n",
    " 'On',\n",
    " 'dessert',\n",
    " 'beef',\n",
    " 'Greek',\n",
    " 'hummus',\n",
    " 'duck',\n",
    " 'He',\n",
    " 'left',\n",
    " 'over',\n",
    " 'perfectly',\n",
    " 'second',\n",
    " 'yummy',\n",
    " 'party',\n",
    " 'mouth',\n",
    " 'where',\n",
    " 'got',\n",
    " 'Thai',\n",
    " 'fine',\n",
    " 'waitress',\n",
    " 'who',\n",
    " 'places',\n",
    " 'eaten',\n",
    " 'thought',\n",
    " 'away',\n",
    " 'pork',\n",
    " 'delish',\n",
    " 'melt',\n",
    " 'cream',\n",
    " 'fact',\n",
    " 'drink',\n",
    " 'never',\n",
    " 'seated',\n",
    " 'pasta',\n",
    " 'full',\n",
    " 'wait',\n",
    " 'Phoenix',\n",
    " 'healthy',\n",
    " 'decor',\n",
    " 'butter',\n",
    " 'chips',\n",
    " 'white',\n",
    " 'salmon',\n",
    " 'though',\n",
    " 'folks',\n",
    " 'special',\n",
    " 'must',\n",
    " 'stop',\n",
    " 'flavorful',\n",
    " 'know',\n",
    " 'seafood',\n",
    " 'each',\n",
    " 'Just',\n",
    " 'patio',\n",
    " 'In',\n",
    " 'house',\n",
    " 'tell',\n",
    " 'And',\n",
    " 'two',\n",
    " 'pleased',\n",
    " 'Pretty',\n",
    " 'warm',\n",
    " 'As',\n",
    " 'cool',\n",
    " 'don',\n",
    " 'think',\n",
    " 'regular',\n",
    " 'until',\n",
    " 'dinner',\n",
    " 'small',\n",
    " 'now',\n",
    " 'new',\n",
    " 'many',\n",
    " 'homemade',\n",
    " 'thin',\n",
    " 'BEST',\n",
    " 'An',\n",
    " 'boyfriend',\n",
    " 'Wow',\n",
    " 'Loved',\n",
    " 'Stopped',\n",
    " 'off',\n",
    " 'touch',\n",
    " 'recommended',\n",
    " 'care',\n",
    " 'stuff',\n",
    " 'wall',\n",
    " 'Mexican',\n",
    " 'Also',\n",
    " 'inexpensive',\n",
    " 'shrimp',\n",
    " 'dressing',\n",
    " 'pita',\n",
    " 'rare',\n",
    " 'outside',\n",
    " 'portion',\n",
    " 'amount',\n",
    " 'glad',\n",
    " 'Always',\n",
    " '2',\n",
    " 'drinks',\n",
    " 'seasoned',\n",
    " 'Today',\n",
    " 'Pho',\n",
    " 'rolls',\n",
    " 'die',\n",
    " 'Will',\n",
    " 'quickly',\n",
    " 'cafe',\n",
    " 'marrow',\n",
    " 'added',\n",
    " 'extra',\n",
    " 'waiter',\n",
    " 'helpful',\n",
    " 'coming',\n",
    " 'beat',\n",
    " 'LOVED',\n",
    " 'wine',\n",
    " 'bartender',\n",
    " 'ambience',\n",
    " 'music',\n",
    " 'playing',\n",
    " 'trip',\n",
    " 'said',\n",
    " 'belly',\n",
    " 'crispy',\n",
    " 'burgers',\n",
    " 'Delicious',\n",
    " 'selections',\n",
    " 'cheese',\n",
    " 'real',\n",
    " 'Subway',\n",
    " 'seriously',\n",
    " 'top',\n",
    " 'itself',\n",
    " 'decorated',\n",
    " 'greeted',\n",
    " 'Bay',\n",
    " 'Some',\n",
    " 'joint',\n",
    " 'different',\n",
    " 'several',\n",
    " 'years',\n",
    " 'ago',\n",
    " 'priced',\n",
    " 'used',\n",
    " 'ladies',\n",
    " 'vegetarian',\n",
    " 'Not',\n",
    " 'Love',\n",
    " 'something',\n",
    " 'flavor',\n",
    " 'What',\n",
    " 'served',\n",
    " 'hot',\n",
    " 'home',\n",
    " 'watch',\n",
    " 'wings',\n",
    " 'feeling',\n",
    " 'bowl',\n",
    " 'drive',\n",
    " 'things',\n",
    " 'hope',\n",
    " 'brunch',\n",
    " 'sides',\n",
    " 'puree',\n",
    " 'friend',\n",
    " 'Waitress',\n",
    " 'couple',\n",
    " 'Everyone',\n",
    " 'customer',\n",
    " 'Now',\n",
    " 'Seriously',\n",
    " 'dark',\n",
    " 'people',\n",
    " 'creamy',\n",
    " 'Fantastic',\n",
    " 'sticks',\n",
    " 'around',\n",
    " 'generous',\n",
    " '8',\n",
    " 'world',\n",
    " 'kind',\n",
    " 'job',\n",
    " 'liked',\n",
    " 'outstanding',\n",
    " 'meat',\n",
    " 'soooo',\n",
    " 'fish',\n",
    " 'summer',\n",
    " 'delightful',\n",
    " 'expect',\n",
    " 'considering',\n",
    " 'potatoes',\n",
    " 'serve',\n",
    " 'may',\n",
    " 'am',\n",
    " 'OMG',\n",
    " 'feels',\n",
    " 'brick',\n",
    " 'oven',\n",
    " 'equally',\n",
    " 'pleasant',\n",
    " 'treat',\n",
    " 'tasted',\n",
    " 'large',\n",
    " 'comfortable',\n",
    " 'fry',\n",
    " 'interesting',\n",
    " 'highly',\n",
    " 'stuffed',\n",
    " 'To',\n",
    " 'lots',\n",
    " 'see',\n",
    " 'perfection',\n",
    " 'impeccable',\n",
    " 'Hot',\n",
    " 'soon',\n",
    " 'tea',\n",
    " 'assure',\n",
    " 'professional',\n",
    " 'told',\n",
    " 'These',\n",
    " 'owners',\n",
    " 'week',\n",
    " 'sure',\n",
    " 'ask',\n",
    " 'tots',\n",
    " 'disappoint',\n",
    " 'enjoy',\n",
    " 'group',\n",
    " 'much',\n",
    " 'favorite',\n",
    " 'manager',\n",
    " 'pizzas',\n",
    " 'lovely',\n",
    " 'such',\n",
    " 'need',\n",
    " 'thumbs',\n",
    " 'choose',\n",
    " 'desserts',\n",
    " 'Perfect',\n",
    " 'do',\n",
    " 'tapas',\n",
    " 'setting',\n",
    " 'take',\n",
    " 'felt',\n",
    " 'friends',\n",
    " 'satisfying',\n",
    " 'grilled',\n",
    " 'especially',\n",
    " 'vibe',\n",
    " 'few',\n",
    " 'seating',\n",
    " 'Italian',\n",
    " 'close',\n",
    " 'him',\n",
    " 'owner',\n",
    " 'Awesome',\n",
    " 'Prices',\n",
    " 'simple',\n",
    " 'One',\n",
    " 'Chicken',\n",
    " 'Chinese',\n",
    " 'paper',\n",
    " 'sat',\n",
    " 'When',\n",
    " 'definately',\n",
    " 'tribute',\n",
    " 'last',\n",
    " 'salsa',\n",
    " 'she',\n",
    " 'late',\n",
    " 'May',\n",
    " 'bank',\n",
    " 'holiday',\n",
    " 'Rick',\n",
    " 'Steve',\n",
    " 'prompt',\n",
    " 'Cape',\n",
    " 'Cod',\n",
    " 'ravoli',\n",
    " 'cranberry',\n",
    " 'mmmm',\n",
    " 'Highly',\n",
    " 'cute',\n",
    " 'less',\n",
    " 'interior',\n",
    " 'performed',\n",
    " 'red',\n",
    " 'velvet',\n",
    " 'cake',\n",
    " 'ohhh',\n",
    " 'hole',\n",
    " 'street',\n",
    " 'combos',\n",
    " '23',\n",
    " 'decent',\n",
    " 'accident',\n",
    " 'happier',\n",
    " 'redeeming',\n",
    " 'Ample',\n",
    " 'Hiro',\n",
    " 'delight',\n",
    " 'positive',\n",
    " 'note',\n",
    " 'provided',\n",
    " 'prime',\n",
    " 'rib',\n",
    " 'section',\n",
    " 'Firehouse',\n",
    " 'refreshing',\n",
    " 'pink',\n",
    " 'char',\n",
    " 'running',\n",
    " 'after',\n",
    " 'realized',\n",
    " 'husband',\n",
    " 'sunglasses',\n",
    " 'chow',\n",
    " 'mein',\n",
    " 'servers',\n",
    " 'imaginative',\n",
    " 'power',\n",
    " 'scallop',\n",
    " 'receives',\n",
    " 'APPETIZERS',\n",
    " 'cocktails',\n",
    " 'handmade',\n",
    " 'give',\n",
    " 'military',\n",
    " 'discount',\n",
    " 'Dos',\n",
    " 'Gringos',\n",
    " 'Update',\n",
    " 'finish',\n",
    " 'included',\n",
    " 'tastings',\n",
    " 'Jeff',\n",
    " 'above',\n",
    " 'beyond',\n",
    " 'expected',\n",
    " 'Really',\n",
    " 'rice',\n",
    " 'spring',\n",
    " 'oh',\n",
    " 'Omelets',\n",
    " 'sexy',\n",
    " 'outrageously',\n",
    " 'flirting',\n",
    " 'hottest',\n",
    " 'person',\n",
    " 'arrived',\n",
    " 'serves',\n",
    " 'wife',\n",
    " 'loves',\n",
    " 'roasted',\n",
    " 'garlic',\n",
    " 'bone',\n",
    " 'another',\n",
    " 'kept',\n",
    " 'bloddy',\n",
    " 'mary',\n",
    " 'Buffet',\n",
    " 'cannot',\n",
    " 'mussels',\n",
    " 'reduction',\n",
    " 'buffets',\n",
    " 'Tigerlilly',\n",
    " 'afternoon',\n",
    " 'personable',\n",
    " 'AND',\n",
    " 'Sooooo',\n",
    " 'Check',\n",
    " 'guys',\n",
    " 'loving',\n",
    " 'son',\n",
    " 'worst',\n",
    " 'venture',\n",
    " 'further',\n",
    " 'Phenomenal',\n",
    " 'Definitely',\n",
    " 'venturing',\n",
    " 'strip',\n",
    " 'return',\n",
    " 'Penne',\n",
    " 'vodka',\n",
    " 'including',\n",
    " 'massive',\n",
    " 'meatloaf',\n",
    " 'wrap',\n",
    " 'tuna',\n",
    " 'NYC',\n",
    " 'bagels',\n",
    " 'Lox',\n",
    " 'capers',\n",
    " 'meet',\n",
    " 'expectations',\n",
    " 'solid',\n",
    " 'bars',\n",
    " 'empty',\n",
    " 'suggestions',\n",
    " 'blanket',\n",
    " 'moz',\n",
    " 'done',\n",
    " 'cover',\n",
    " 'subpar',\n",
    " 'bathrooms',\n",
    " 'fianc√©',\n",
    " 'middle',\n",
    " 'Mandalay',\n",
    " 'highlights',\n",
    " 'nigiri',\n",
    " 'cut',\n",
    " 'piece',\n",
    " 'flavored',\n",
    " 'Voodoo',\n",
    " 'gluten',\n",
    " 'free',\n",
    " 'immediately',\n",
    " 'diverse',\n",
    " 'reasonably',\n",
    " 'Restaurant',\n",
    " 'DELICIOUS',\n",
    " 'hands',\n",
    " 'metro',\n",
    " 'Bacon',\n",
    " 'hella',\n",
    " 'salty',\n",
    " 'menus',\n",
    " 'handed',\n",
    " 'no',\n",
    " 'listed',\n",
    " 'waitresses',\n",
    " 'Lordy',\n",
    " 'Khao',\n",
    " 'Soi',\n",
    " 'missed',\n",
    " 'curry',\n",
    " 'lovers',\n",
    " 'terrific',\n",
    " 'thrilled',\n",
    " 'accommodations',\n",
    " 'daughter',\n",
    " 'modern',\n",
    " 'hip',\n",
    " 'maintaining',\n",
    " 'coziness',\n",
    " 'weekly',\n",
    " 'haunt',\n",
    " 'hits',\n",
    " 'lacking',\n",
    " 'quantity',\n",
    " 'Lemon',\n",
    " 'raspberry',\n",
    " 'cocktail',\n",
    " 'Interesting',\n",
    " 'crepe',\n",
    " 'station',\n",
    " 'bits',\n",
    " 'original',\n",
    " 'preparing',\n",
    " 'egg',\n",
    " 'satisfied',\n",
    " 'heard',\n",
    " 'exceeding',\n",
    " 'dreamed',\n",
    " 'serivce',\n",
    " 'inviting',\n",
    " 'mixed',\n",
    " 'mushrooms',\n",
    " 'yukon',\n",
    " 'gold',\n",
    " 'corn',\n",
    " 'beateous',\n",
    " 'tartar',\n",
    " 'Extremely',\n",
    " 'Tasty',\n",
    " 'Jamaican',\n",
    " 'mojitos',\n",
    " 'rich',\n",
    " 'accordingly',\n",
    " 'wrapped',\n",
    " 'dates',\n",
    " 'unbelievable',\n",
    " 'BARGAIN',\n",
    " 'Otto',\n",
    " 'welcome',\n",
    " 'pho',\n",
    " 'whenever',\n",
    " 'sporting',\n",
    " 'events',\n",
    " 'walls',\n",
    " 'covered',\n",
    " 'TV',\n",
    " 'hardest',\n",
    " 'decision',\n",
    " 'Honestly',\n",
    " 'M',\n",
    " 'supposed',\n",
    " 'providing',\n",
    " 'flavourful',\n",
    " 'delights',\n",
    " 'Much',\n",
    " 'AYCE',\n",
    " 'lighting',\n",
    " 'set',\n",
    " 'mood',\n",
    " 'Owner',\n",
    " 'peanut',\n",
    " '7',\n",
    " 'exquisite',\n",
    " 'boot',\n",
    " 'Plus',\n",
    " 'bucks',\n",
    " 'Thus',\n",
    " 'visited',\n",
    " 'year',\n",
    " 'Veggitarian',\n",
    " 'platter',\n",
    " 'cant',\n",
    " 'Madison',\n",
    " 'Ironman',\n",
    " 'chefs',\n",
    " 'goat',\n",
    " 'taco',\n",
    " 'skimp',\n",
    " 'wow',\n",
    " 'FLAVOR',\n",
    " 'Bachi',\n",
    " 'Burger',\n",
    " 'Pizza',\n",
    " 'Salads',\n",
    " 'pulled',\n",
    " 'incredibly',\n",
    " 'prepared',\n",
    " 'dine',\n",
    " 'charming',\n",
    " 'outdoor',\n",
    " 'high',\n",
    " 'Back',\n",
    " 'BBQ',\n",
    " 'lighter',\n",
    " 'fare',\n",
    " 'pricing',\n",
    " 'public',\n",
    " 'old',\n",
    " 'ways',\n",
    " '20',\n",
    " 'exceptional',\n",
    " 'reviews',\n",
    " 'months',\n",
    " 'later',\n",
    " 'returned',\n",
    " 'Favorite',\n",
    " 'shawarrrrrrma',\n",
    " 'black',\n",
    " 'eyed',\n",
    " 'peas',\n",
    " 'UNREAL',\n",
    " 'vinaigrette',\n",
    " 'overall',\n",
    " 'truly',\n",
    " 'unbelievably',\n",
    " 'delicioso',\n",
    " 'Of',\n",
    " 'vegetables',\n",
    " 'driving',\n",
    " 'Tucson',\n",
    " 'Chipotle',\n",
    " 'BETTER',\n",
    " 'Classy',\n",
    " 'appetizers',\n",
    " 'succulent',\n",
    " 'Baseball',\n",
    " 'app',\n",
    " 'multiple',\n",
    " 'treated',\n",
    " 'genuinely',\n",
    " 'enthusiastic',\n",
    " 'evening',\n",
    " 'life',\n",
    " 'bathroom',\n",
    " 'door',\n",
    " 'Outstanding',\n",
    " 'Server',\n",
    " 'handling',\n",
    " 'rowdy',\n",
    " 'Would',\n",
    " 'craving',\n",
    " 'deserves',\n",
    " 'space',\n",
    " 'tiny',\n",
    " 'elegantly',\n",
    " 'customize',\n",
    " 'usual',\n",
    " 'Eggplant',\n",
    " 'Green',\n",
    " 'Bean',\n",
    " 'stir',\n",
    " 'part',\n",
    " 'dinners',\n",
    " 'outshining',\n",
    " 'Halibut',\n",
    " 'Def',\n",
    " 'ethic',\n",
    " 'continue',\n",
    " 'andddd',\n",
    " 'date',\n",
    " 'anyone',\n",
    " 'past',\n",
    " 'walked',\n",
    " 'located',\n",
    " 'Crystals',\n",
    " 'shopping',\n",
    " 'mall',\n",
    " 'Aria',\n",
    " 'summarize',\n",
    " 'nay',\n",
    " 'transcendant',\n",
    " 'nothing',\n",
    " 'brings',\n",
    " 'joy',\n",
    " 'memory',\n",
    " 'pneumatic',\n",
    " 'condiment',\n",
    " 'dispenser',\n",
    " 'Kids',\n",
    " 'kiddos',\n",
    " 'Cooked',\n",
    " 'reminds',\n",
    " 'mom',\n",
    " 'pop',\n",
    " 'shops',\n",
    " 'San',\n",
    " 'Francisco',\n",
    " 'Area',\n",
    " 'Buldogis',\n",
    " 'Gourmet',\n",
    " 'Dog',\n",
    " 'possible',\n",
    " 'petty',\n",
    " 'iced',\n",
    " 'Come',\n",
    " 'hungry',\n",
    " 'leave',\n",
    " 'eating',\n",
    " 'First',\n",
    " 'become',\n",
    " 'looked',\n",
    " 'overwhelmed',\n",
    " 'needs',\n",
    " 'stayed',\n",
    " 'end',\n",
    " 'From',\n",
    " 'companions',\n",
    " 'texture',\n",
    " 'No',\n",
    " 'complaints',\n",
    " 'expert',\n",
    " 'connisseur',\n",
    " 'topic',\n",
    " 'nicest',\n",
    " 'across',\n",
    " 'biscuits',\n",
    " 'absolutley',\n",
    " 'Steiners',\n",
    " 'familiar',\n",
    " 'Anyway',\n",
    " 'FS',\n",
    " 'Each',\n",
    " 'mention',\n",
    " 'combination',\n",
    " 'pears',\n",
    " 'almonds',\n",
    " 'big',\n",
    " 'winner',\n",
    " 'spicier',\n",
    " 'prefer',\n",
    " 'ribeye',\n",
    " 'mesquite',\n",
    " 'gooodd',\n",
    " 'mouthful',\n",
    " 'enjoyable',\n",
    " 'relaxed',\n",
    " 'venue',\n",
    " 'couples',\n",
    " 'groups',\n",
    " 'etc',\n",
    " 'Nargile',\n",
    " 'tater',\n",
    " 'southwest',\n",
    " 'vanilla',\n",
    " 'smooth',\n",
    " 'profiterole',\n",
    " 'choux',\n",
    " 'pastry',\n",
    " 'Im',\n",
    " 'AZ',\n",
    " 'margaritas',\n",
    " 'trimmed',\n",
    " '70',\n",
    " 'claimed',\n",
    " '40',\n",
    " 'handled',\n",
    " 'beautifully',\n",
    " 'jewel',\n",
    " 'Las',\n",
    " 'exactly',\n",
    " 'hoping',\n",
    " 'find',\n",
    " 'nearly',\n",
    " 'ten',\n",
    " 'living',\n",
    " 'isn',\n",
    " 'establishment',\n",
    " 'toro',\n",
    " 'tartare',\n",
    " 'cavier',\n",
    " 'extraordinary',\n",
    " 'thinly',\n",
    " 'sliced',\n",
    " 'wagyu',\n",
    " 'truffle',\n",
    " 'How',\n",
    " 'decide',\n",
    " 'CONCLUSION',\n",
    " 'filling',\n",
    " 'meals',\n",
    " 'daily',\n",
    " 'specials',\n",
    " 'pancake',\n",
    " 'crawfish',\n",
    " 'monster',\n",
    " 'fried',\n",
    " 'eggs',\n",
    " 'funny',\n",
    " 'Mom',\n",
    " 'multi',\n",
    " 'grain',\n",
    " 'pumpkin',\n",
    " 'pancakes',\n",
    " 'pecan',\n",
    " 'fluffy',\n",
    " 'Cant',\n",
    " 'hand',\n",
    " 'pastas',\n",
    " 'Give',\n",
    " 'By']\n",
    "print('Keywords list length is {} words long'.format(len(keywords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 196\n"
     ]
    }
   ],
   "source": [
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sentiment_raw[str(key)] = sentiment_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "data = sentiment_raw[keywords]\n",
    "target = sentiment_raw['sentiment']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.685\n",
      "Testing on Sample: 0.804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7 ,  0.67,  0.72,  0.69,  0.7 ,  0.7 ,  0.64,  0.78,  0.67,  0.76])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity is 0.874384236453202\n",
      "Specificity is 0.7558922558922558\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(target, y_pred)\n",
    "print('Sensitivity is {}'.format(matrix[1,1]/(matrix[0,1]+matrix[1,1])))\n",
    "print('Specificity is {}'.format(matrix[0,0]/(matrix[0,0]+matrix[1,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier seems to be overfitting the data when I conduct a one time holdout of 20% and when we conduct a cross-validation with 10 folds it also confirms that there could be overfitting.  The sensitivity is better and has increased.  The specificity is the highest of all the classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Evaluation: ###\n",
    "### The classifiers with a lot of keywords in the keywords tend to overfit.  It can be readily seen when we conduct a test/train split with a 20% holdout.  I believe that classifier that seems to work the best without overfitting is the classifier with a keywords list of 23 words.  The features that seem to be the most helpful in the performance are the top 5 positive sentiment words.  You can see that with just the top 5 positive sentiment words we are able to get a sensitivity score of about 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
